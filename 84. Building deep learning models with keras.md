# creating a keras model
## model building steps
- specify architecture
- compile
- fit
- predict

__model specification__
> import numpy as np  
> from keras.layers import Dense  
> from keras.models import Sequential  
> predictors = np.loadtxt('predictors_data.csv', delimiter = ',')  
> n_cols = predictors.shape[1]  
> model = Sequential()  
> model

# Compiling and fitting a model
## Why you need to compile your model
- specify the optimizer
  - many options and mathematically complex
  - 'Adam' is uaually a good choice
- loss function
- control the learning rate
  - 'mean_squared_error' common for regression

__compiling a model__
> n_cols = predictors.shape[1]  
> model = Sequential()  
> model.add(Dense(100, activation = 'relu', input_shape = (n_cols,)))  
> model.add(Dense(100, activation = 'relu'))  
> model.add(Dense(1))  
> model.compile(optimizer = 'adam', loss = 'mean_squared_error')

## What is fitting a model
- applying backpropagation and gradient descent with your data to update the weights
- scaling data before fitting can ease optimization

__fitting a model__
> n_cols = predictors.shape[1]  
> model = Sequential()  
> model.add(Dense(100, activation = 'relu', input_shape = (n_cols, )))  
> model.add(Dense(100, activation = 'relu'))  
> model.add(Dense(1))  
> model.compile(optimizer = 'adam', loss = 'mean_squared_error')  
> model.fit(predictors, target)

# Classification models
## Classification
- 'categorical_crossentropy' loss function
- similar to log loss: Lower is better
- add metrics = ['accuracy'] to compile step for easy-to-understand diagnostics
- output layer has separate node for each possible outcome, and uses 'softmax' activation(to make sure predictions sum to 1, can be interpreted as probability )

__Classification__
> from keras.utils import to_categorical  
> data = pd.read_csv('basketball_shot_log.csv')  
> predictors = data.drop(['shot_result'], axis = 1).as_matrix()  
> target = to_categorical(data.shot_result)  
> model = Sequential()  
> model.add(Dense(100, activation = 'relu', input_shape = (n_cols,)))  
> model.add(Dense(100, activation = 'relu'))  
> model.add(Dense(2, activation = 'softmax'))  
> model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics ['accuracy'])  
> model.fit(predictors, target)

# Using models
- save
- reload
- make predictions

__Saving, reloading and using your Model__
> from keras.models import load_model  
> model.save('model_file.h5')  
> my_model = load_model('my_model.h5')  
> predictions = my_model.predict(data_to_predict_with)  
> probability_true = predictions[:,1]

__verifying model structure__
> my_model.summary()  
> [out] ...