# Will learn
- extracting, filtering, and transforming data from DataFrames
- advanced indexing with multiple levels
- tidying, rearranging and restructuring your data
- pivoting, melting, and stacking DataFrames
- Identifying and splitting DataFrames by groups

# Indexing DataFrames
__only column-row is ok__
> df[column][row]  
> ~~df[row][column]~~

__column attribute and row label__
> df.column['row index']

__use the .loc accessor__
> df.loc['row', 'column']  
> df.loc[:, 'column']

__use the .iloc accessor__
> df.iloc[row number, column number]

__selecting only some columns__
> df[[column1, columm2]]


# Slicing DataFrame

__selecting a column (that is, Series)__
> df['column']  
> df['column'][number index]

## __using .loc[ ]__

__all rows, some column__
> df.loc[:, 'column']

__some rows, all column__
> df.loc['row', :]

__some rows, some columns__
> df.loc['row', 'column']

## __using .iloc[ ]__
df.iloc['row', 'column']

NOTE : don't forget the square bracket inside square bracket.(if the range is a list)

__Series__
> df['column']

__Single column DataFrame__
> df[['column']]

__select with condition__
> df['column' : 'column' : -1] # will reverse  
> df['column' : 'column' : 2 ] # will select with skip

# Filtering DataFrames

1. Creating a Boolean Series
   > df.column > 100
2. Filtering with a Boolean Series
   > df[df.column > 100]

__combining filters__
> df[(df.column1 > 100) & (df.column2 < 100)] # will return result match both conditions

> df[(df.column1 > 100) | (df.column2 < 100)] # will return either condition

__copy DataFrame__
> copied = df.copy()

## DataFrames with zeros and NaNs

NOTE : 
- all : and
- any : or

__select columns with all nonzeros : all( )__
> df.loc[:, df.all()]

__select columns with any nonzeros : any( )__
> df.loc[:, df.any()]

__select columns with any NaNs : isnull().any()__
> df.loc[:, df.isnull().any()]

__select columns without NaNs : notnull().all()__
> df.loc[: ,df.notnull().all()]

__drop rows with any NaNs__
> df.dropna(how = 'any')

__filtering a column based on another__
> df.column1[df.column2 > 100]

__drop column that has too many missing values__
> titanic.dropna(thresh=1000,axis='columns').info()


# Transforming DataFrames
## DataFrame vectorized methods

__floor division__
> df.floordiv(12) # convert to dozen unit, 無條件捨去

## NumPy vectorized functions
> np.floor_divided(df,12) # convert to dozen unit

## Plain Python functions
> def dozen(x):  
> return x//12  
> df.apply(dozen)

__lambda__
>df.apply(lambda x: x//12)

__storing a transformation__
>df[column_dozen] = df.column.floordiv(12)

__check the index__
> df.index

__check the column__
> df.columns

## working with string values

__upper string index__
> df.index = df.index.str.upper()

NOTE : map(function, iterator) will return map object.
there is no apply funciton for index, map is like apply.

__lower string index__
> df.index = df.index.map(str.lower)

__create new column using other columns__
> df['new column'] = df.column1 + df.column2

__map DataFrame with Dictionary__
> dict = {A:a, B:b}  
> data[new column] = data[column].map(dict)