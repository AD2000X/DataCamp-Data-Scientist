# Categoricals and groupby

__count__
> data.loc[data[column] == condition].count()

__groupby and count__
> data.groupby('column').count()

means split by column and apply count function on each group.

- Steps:
  1. split
  2. apply
  3. combine


## Other Aggregation/Reduction
- mean()
- std()
- sum()
- first(), last()
- min(), max()

__groupby column1 and sum single column2__
> data.groupby('column1')['column'2].sum()

__groupby multiple columns and sum__
> data.groupby('column')[['column1', 'column2']].sum()

__groupby multi-level index and mean__
> data.groupby(level = [column1, column2]).mean()

## Categorical data
- Advantage
  - use less memory
  - speed up operations like groupby()
  
__unique method__
> data[column].unique()  

__transform to category__
> data[column].astype('category')

# Groupby and aggregation

__multiple aggregations, list of string names__
> data.groupby('column')[target column].agg(['max', 'sum'])

__custom aggregation__
> def difference(series):  
> return series.max() - series.min()  
> data.groupby('column')['target column'].agg(difference)

__custom aggreagtion : dictionaries__
> data.groupby('columns')[target columns].agg({column1 : sum, column2 : difference})

NOTE : key = column, value = aggregation function

# Groupby and transformation

__z-score__
> def zscore(series):  
> return(series - series.mean())/series.std()
> data.groupby('column')[target column].transform(zscore)

## __apply transformation and aggregation__

__difference between aggregation and transformation__
- transformation can broadcast across the whole group.
- transformation can return values with same index
- agg method : reduction, transform method : function elementwise to groups.

# Groupby and filtering

__groups attribute__
> G = data.groupby(column)  
- G.groups will return groups name, types are dictionary.
- keys() are group name
- values() are group value
  
__look up for string__
>for group_name, group in data:  
>ave = group.loc[group[column]].str.contains('keyword'), 'column'].mean()