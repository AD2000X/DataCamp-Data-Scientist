Have Learned:
- writing custom functions
- Using custom functions in data science

Will Learn:
- List comprehensions
  - wrangle data to create other lists)

- Iterators
  - met before
  - Rapidly iterate data science protocols and procedures over stes of objects.  



# Iterators in PythonLand

iterating with a for loop  

## iterable
- example : list , strings , dictionaries, file connections
- an object with an associated __iter( )__ method
- applying __iter( )__ to an iterable creates an iterator
(like str(), float() etc...)
## iterator
- produce next value with __next( )__

iterating over iterables using next()  
>it = iter(word)  
next(it)

iterating all at once with  *  
>it = iter(word)  
print(*it)

## Iterating over Dictionaries
>for key, value in dict.items():  
&nbsp;&nbsp;&nbsp;&nbsp;expression  


## Iterating over file connections
>file = open('file name)  
it = iter(file)  
print(next(it))  
'This is the first line.'  
print(next(it))  
'This is the second line'  

### __What For Loop is Doing__

take iterable, create associated iterator object and iterate over it!!!


# Playing with iterators

## Using enumerate( ) to add a counter to iterable
__NOTE : transform to list to print out__   
l = list(enumerate(list_name))  
in for loop, enumerate will add index to list.
> for index, value in enumerate(list, start = 10):  
print(index, value) 

## Using zip to concate iterable
>list1 &nbsp; list2  
z = zip(list1, list2)  
z = list(z)  
print(z)  
[OUT] [(list1[0], list2[0]), (list1[1],list2[1]) ...]

print with *  
>print(z*)  
[OUT] (list[0], list2[0])...)(list1[1], list2[1])

## Using zip to unpack
>list1 &nbsp; list2  
for z1, z2 in zip(list1, list2)  
print(z1, z2)  


# Using iterators to load large files into memory
load data with read_csv( )  
specify the chunk by __chunksize__

>for chunk in pd.read_csv('data.csv', chunksize = 10000):  
total = sum(chunk['column'])  
print total

> for chunk in pd.read_csv('tweets.csv', chunksize = 10):  
means ten rows are extracted