# Importing data from the internet

## __Will Learn__
- import and locally save datasets from the web
- load datasets into pandas DataFrames
- make http requests (GET request)
- scrape web data such as HTML
- parse HTML into usefull data (__BeautifulSoup__)
- use the __urllib__ and __requests__ package

## The urllib package
- provides interface for fetching data across the web
- urlopen() like open() function, it accepts URLs instead of file names

__automate file download in Python__
>from urllib.request import urlretrieve  
url = 'website'
urlretrieve(url, filename)

__url to DataFrame__
> xl = pd.read_excel(url)  
> print(xl.keys())  
> print(xl['sheetname'].head())


# HTTP requests to import files from the web

## URL
- uniform/universal resource locator
- reference to web resources
- focus : web address
- Ingredients:
  - protocol indentifier - http:
  - resource name
  - combination of web address
- These specify web addresses uniquely


## HTTP
- hyper text transfer protocol
- foundation of data communication for the web
- HTTPS - more secure form of HTTP
- Going to a website = sending HTTP request
  - __GET__ request
- urlretrieve( ) performs a GET request
- HTML - HyperText Markup Language

__GET requests using urllib__
>from urllib.request import urlopen, Request  
url = 'website'  
request = Request(url)  
response = urlopen(request)  
html = response.read( )  
response.close()

__GET requests using request__
- import package
- specify url
- request.get url
- trun into txt file
>import requests  
url = 'website'  
r = request.get(url)  
text = r.text


# Scraping the web in Python

## HTML
- mix of unstructured and structured data
- structured data:
  - has pre-defined data model, or
  - organized in a defined manner
- Unstructured data : neither of these properties

## BeautifulSoup
>import package  
url = 'website'  
r = request.get(url)  
html_doc = r.txt  
soup = BeautifulSoup(html_doc)

__prettified soup__
soup.prettify()

__Other Methods__
>soup.title
>soup.text
>soup.get_text()

__find_all()__
>for link in soup.find_all('a'):  print(link.get('herf'))

__NOTE__ :  hyperlinks are defined by the HTML tag <a>

