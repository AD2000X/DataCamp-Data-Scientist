# Visualizing hierarchies
## Visualisations communicate insight
- 't-SNE': creates a 2D map of a dataset(later)
- 'Hierarchical clustering' (this video)

## A hierarchy of groups
- groups of living things can form a hierarchy
- clusters are contained in one another

## Eurovision scoring dataset
- countries gave scores to songs performed at the Eurovision 2016
- 2D array of scores
- rows are countries, column are songs

## Hierarchical clustering
- every country begins in a separate cluster
- at each step, the two closest clusters are merged
- continue until all countries in a single cluster
- this is 'agglomerative' hierarchical clustering

## the dendrogram of a hierarchical clustering
- read from the bottom up
- vertical lines represent clusters

__Hierarchical clustering with SciPy__
- given samples(the array of scores), and country_names

> import matplotlib.pyplot as plt  
> from scipy.cluster.hierarchy import linkage, dendrogram  
> mergins = linkage(samples, method = 'complete')  
> dendrogram(mergins, labels = country_names, leaf_rotation = 90, leaf_font_size = 6)  
> plt.show()

# Cluster labels in hierarchical clustering
## Cluster labels in hierarchical clustering
- not only a visualisation tool!
- cluster labels at any intermediate stage can be recovered
- for use in e.g. cross-tabulations

## Intermediate clustering & height on dendrogram
- e.g. at height 15: bulgaria, cyprus, greece are on cluster
- russia and doldova are another
- armenia in a cluster on its own

## Dendrograms show cluster distances
- height on dendrogram = distance between merging clusters
- e.g. clusters with only cyprus and greece had distance approx 0.6
- this new cluster distance approx 0.12 from cluster with only bulgaria

## Intermediate clusterings & height on dendrogram
- height on dendrogram specifies max distance between merging clusters
- don't merge clusters further apart than this (e.g. 15)

## Distance between clusters
- defined by a 'linkage method'
- specified via method parameter, e.g. linkage(samples, method = 'complete')
- in 'complete' linkage: distance between clusters is max distance between their samples
- different linkage method, different hierarchical clustering

## Extracting cluster labels
- use the fcluster method
- returns a NumPy array of cluster labels

## Extracting cluster labels using fcluster
> from scipy.cluster.hierarchy import linkage  
> mergings = linkage(samples, method = 'complete')  
> from scipy.cluster.hierarchy import fcluster  
> labels = fcluster(mergings, 15, criterion = 'distance')  
> print(labels)  
> [9 8 11 20 2 1 17 14 ...]

## Aligning cluster labels with country names
- given a list of strings __country_names__:
> import pandas as pd  
> pairs = pd.DataFrame({'labels': labels, 'countries': country_names})  
> print(pairs.sort_values('labels))  
>  countries labels  
> 5 belarus 1  
> 40 ukraine 1  
> 17 georgia 1  
> ...

# t-SNE for 2-dimensional maps
- t-SNE = 't-distributed stochastic neighbor embedding'
- maps samples to 2D space (or 3D)
- map approximately preserves nearness of samples
- great for inspecting datasets

## t-SNE on the iris dataset
- iris dataset has 4 measurements, so samples are 4-dimensional
- t-SNE maps samples to 2D space
- t-SNE didn't know that there were different species
- ...yet kept the species most sepearate

## Interpreting t-SNE scatter plots
- 'versicolor' and 'virginica' harder to distinguish from one another
- consistent with k-means inertia plot: could argue for 2 clusters, or for 3

## t-SNE in sklearn
- 2D NumPy array samples
- list species giving species of labels as number(0,1 or 2)
> print(samples)  
> [out] [5 3.3 1.4 0.2 ...]  
> print(species)  
> [out] [0,0,1,2,...]

## t-SNE in sklearn
> import matplotlib.pyplot as plt  
> from sklearn.manifold import TSNE  
> model = TSNE(learning_rate = 100)  
> transformed = model.fit_transform(samples)  
> xs = transformed[:,0]  
> yx = transformed[:,1]  
> plt.scatter(xs, ys, c = species)  
> plt.show()

## t-SNE has only fit_transform()
- has a fit_transform() method
- simultaneously fit the model and transforms the data
- has no separate __fit)__ or __transform()__ methods
- can't extend the map to include new data samples
- must start over each time!

## t-SNE learning rate
- choose learning rate for the dataset
- wrong choice: points bunch together
- try values between 50 and 200

## Different every time
- t-SNE features are different every time
- piedmont wines, 3 runs, 3 different scatter plots!
- ...however: the wine varieties(= color) have same position relative to one another