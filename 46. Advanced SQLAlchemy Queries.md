# Calculating Values in a Query
math operators work differently on different data types

__calculating difference__
> stmt = select([census.columns.age, census.columns.pop2008 - census.columns.pop2000]).label('pop_change')  
> stmt = stmt.group_by(census.columns.age)  
> stmt = stmt.order_by(desc('pop_change'))  
> stmt = stmt.limit(5)  
> results = connection.execute(stmt).fetchall()

## Case Statement
- used to treat data differently based on a condition
- accept a list of conditions to match and a column to return if the condition matches
- the list of conditions ends with an else clause to determine what to do when a record doesn't match any prior conditions

__Case Example__
> from sqlalchemy import case  
> stmt = select([func.sum([case(census.columns.state == 'New York', census.columns.pop2008)], else_ = 0))])  
> results = connection.execute(stmt).fetchall()

## Cast Statement
- convert data to another type
- useful for converting
  - integers to floats for division
  - strings to dates and times
- accept a column or expression and the target Type

__Percentage Example__
> from sqlalchemy import case, cast, Float  
> stmt = select([(func.sum(case([(census.columns.state == 'New York', census.columns.pop2008)],else_ = 0)) / cast(func.sum(census.columns.pop2008),Float) * 100).label('ny_percent')])  
> results = connection.execute(stmt).fetchall()

# SQL Relationships
## Relationships
- allow us to avoid duplicate data
- make it easy to change things in one place
- useful to break out information from a table we don't need very often
- Example two table : census, state_fact

__automatic joins__
> stmt = select([census.columns.pop2008, state_fact.columns.abbreviation]  
> results = connection.execute(stmt).fetchall()  

## Join
- accept a Table and an optional expression that explains how the two tables are related
- the expression is not needed if the relationship is predefined and available via reflection
- comes immediately after the SELECT() clause and prior to any WHERE(), ORDER_BY or GROUP_BY() clauses.

## Select_from
- used to replace default, derived FROM clause with a join
- wraps the join() clause

__select_from example__
> stmt = select([func.sum(census.columns.pop2000)])  
> stmt = stmt.select_from(census.join(state_fact))
> stmt = stmt.where(state_fact.columns.circuit_court == '10')
> result = connection.execute(stmt).scalar()

__join tables without predefined relationship__
- join accepts a Table and an optional expression that explains how the two tables are related.
- will only join data that match between the two columns(intersection)
- avoid joining on columns of different types

__select_from example__
> stmt = select([func.sum(census.columns.pop2000)])  
> stmt = stmt.select_from(census.join(state_fact, census.columns.state == state_fact.columns.name))  
> stmt = stmt.where(state_fact.columns.census_division_name == 'East South Central')  
> result = connection.execute(stmt).scalar()

# Working with Hierarchical Tables
## Hierarchical Tables
- Contain a relationship with themselves
- commonly found in orgainzational, geographic, network and graph

## Hierarchical Tables - alias()
- requires a way to view the table via multiple names
- creates a unique reference that we can use

__querying hierarchical data__
> managers = employees.alias()  
> stmt = select([managers.columns.name.label('manager'), employees.columns.name.label('employee')])  
> stmt = stmt.select_from(employees.join(managers, managers.columns.id == employees.columns.manager)  
> stmt = stmt.order_by(manager.columns.name))

## Group_by and Func
- it's important to target group_by() at the right alias
- be careful with what you perfrom functions on
- if you don't find yourself using both the alias and the table name for a query, don't creat the alias at all.

__querying hierarchical data__
> managers = employees.alias()  
> stmt = select([managers.columns.name, func.sum(employees.column.sal)])  
> stmt = stmt.select_from(employees.join(managers, managers.columns.id == employees.columns.manager))  
> stmt = stmt.group_by(managers.columns.name)

# Handling Large ResultSets
## Dealing with Large Results
- fetchmany() let us specify how many rows we want to act upon.
- we can loop over fetchmany()
- it returns an empty list when there are no more record
- we have to close the ResultProxy afterwords

__fetching many rows__
> while more_results:  
> partial_results = results_proxy.fetchmany(50)  
> if partial_results == []  
> more_result = False  
> for row in partial_results:
> state_count[row.state] += 1  
> results_proxy.close()