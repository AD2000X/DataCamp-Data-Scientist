# Indexing time series

## Using pandas to read datatime objects
- read_csv() function
  - can read strings into datatime objects
  - need to specify 'parse_dates = True'
- ISO 8601 format
  - yyyy-mm-dd hh:mm:ss

__pandas dates__
> import pandas as pd  
> data = pd.read_csv('filename', parse_date = True, index_col = 'Date')

__selecting single datatime__
> data.loc['datetime', 'column']

__selecting whole day__
> data.loc['2019-02-20'] # this will return all datetime on this day

__partial datetime string selection__
- alternative formats:
  - data.loc['February 20, 2019']
  - data.loc['2019-Feb-20']
- Whole month : data.loc['2019-2']
- Whole year : data.loc['2019']

__slicing using datas/times
> data.loc['2019-2-20' : '2019-2-21']

__convert strings to datatime__  
> evening_2_20 = pd.to_datetime(['2019-2-20 20:00', ... , '2019-2-20 23:00'])

specify format
> df = pd.to_datetime(date_list,format = %Y-%m-%d %H%M%S)

__reindexing DataFrame__
> data.reindex(enening_2_20) #use evening_2_20 to reindex

NOTE : this will fill the matching entries and fill other with NaN

__filling missing values__  

forward fill  
> data.reindex(evening_2_20, method = 'ffill')  

backward fill
> data.reindex(evening_2_20, method = 'bfill')

NOTE : using other DataFrame's index for reindex
> data.reindex(data2.index)

# Resampling time series data

- statistical methods over different time intervals
  - mean(), sum(), count(), etc
- Down-sampling
  - reduce datetime rows to slower frequency 
    - ex : weekly to yearly
- Up-sampling
  - increase datetime row to faster frequency 
    - ex : weekly to daily

## resampling frequencies
- minute : min, T
- hour : H
- day : D
- business day : 'B'
- week : W
- month : M
- quarter : Q
- year : A

__aggregating means__
> daily_mean = data.resample('D').mean()

NOTE : 
1. string after resample method to specify frequency
2. resample method chained with statistical methods
3. result is a DataFrame of mean with daily frequency 
4. Non-numerical column is ignored
5. missing day will be fill with NaN


__multiplying frequencies__(downsampling)  
> data.loc[:, 'column'].resample('2W').sum()

__upsampling__
> two_days = data.loc['2019-2-20' : '2019-2-22', 'column']

__upsampling and filling__
> two_days.resample('4H').ffill()

__smoothing data : rolling method__  
window = number of observations used for calculated statistics.

# Manipulating time series data

## __string method ( for string column)__
__upper__
> data['column'].str.upper()

__substring matching__
> data['column'].str.contains('keyword')  #will return booleans

__boolean reduction__  
True = 1  
False = 0  

> data['column'].str.contains('keyword').sum() # will return a number of keyword


__strip extra whitespace__
> data.columns.str.strip()
## __datetime method (for datetime column)__
> data['column'].dt.hour

__set timezone : dt.tz_localize__
> central = data['column'].__dt.tz_localize__('US/Central')

__convert timezone : dt.tz_convert__
>central.__dt.tz_convert__('US/Eastern')

__method chaining__
> data['column'].dt.tz_localize('US/Central').dt.tz_convert('US/Eastern')

__unsample data and interpolate data__
> data.resample('up-sample').first() # first() will fill NaN inbetween  
> data.resample('up-sample').first().interpolate('linear')

# Time series visualization

## __Topic__
- line types
- plot types
- subplots

__pandas plot__
> data['column'].plot()  
> plt.show

__title and label__
> data['column'].plot(title = 'title')  
> plt.ylabel('label name') # x label is index by default, we need to add y axis, y label name and title

__plot one week__
> data.loc['time period', 'column'].plot(title)  
> plt.ylabel('label name')

[__plot styles__](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html)
> plot(style = 'k.-)

## more plot styles
- style format string
1. color (k : black)
2. marker(. : dot)
3. line type(- : solid)

|color|marker|line|
|-----|------|----|
r : red|o : circle| : :dotted
g : green|* : star| - : dashed
b : blue|s : square|   
c : cyan|+ : plus|

## area plot (像積分的圖)
data['column'].plot(kind = 'area')

__multiple columns__
>data.loc['2019', [column1, column2]].plot() 

NOTE : easily mess, use subplots

__subplots__
> data.loc['2019', [column1, column2]].plot(subplot = True)