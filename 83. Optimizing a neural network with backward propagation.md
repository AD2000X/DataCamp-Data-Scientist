# The need for optimization

## Predictions with multiple points
- making accurate predictions gets harder with more points
- at any set of weights, there are many value of the error
- corresponding to the many points we make predictions for

## LOSS function
- aggregates errors in predictions from many data points into single number
- measure of model's predictive performance
- lower loss function value means a better model
- goal: find the weight that gives the lowest value for the loss function
- gradient descent

## Gradient descent
- imagine you are in a pitch dark field
- want to find the lowest point
- feel the ground to see how it slopes
- take a small step downhill
- repeat until it is uphill in every direction

## Gradient descent steps
- start at random point
- until you are somewhere flat:
  - find the slope
  - take a step downhill

# Gradient descent
- if the slope is positive:
  - going opposite the slope means moving to lower numbers
  - subtract the slope from the current value
  - too big a step might lead us astray
- solution: learning rate
  - update each weight by subtracting **learning rate * slope**

## Slope calculation
to calculate the slope for a weight, need to multiply:
(w.r.t = with respect to)
- slope of the loss function w.r.t value at the node we feed into
  - 2 * (error)
- the value of the node that feeds into our weight
  - input value
- slope of the activation function w.r.t value we feed into
- weight - learning rate * (slope)
- slope = 2 * input_data * error

__code to calculate slopes and update weights__
> import numpy as np  
> weights = np.array([1,2])  
> input_data = np.array([3,4])  
> target = 6  
> learning_rate = 0.01  
> preds = (weights * input_data).sum()  
> error = preds - target  
> print(error)  
> [out] 5

> gradient = 2 * input_data * error  
> gradient  
> [out] array([30,40])  
> weights_updated = weight - learning_rate * gradient  
> preds_updated = (weights_updated * input_data).sum()  
> error_updated = preds_updated - target  
> print(error_updated) = -2.5

# Backpropagation
- allows gradient descent to update all weights in neural network(by getting gradients for all weights)
- comes from chain rule of calculus
- important to understand the process, but you will generally use a library that implements this

## Backpropagation process
- trying to estimate the slope of the loss function w.r.t each weight
- do forward propagation to calculate predictions and errors

<br>

- go back one layer at a time
- gradients for weight is product of:
  - 1. node value feeding into that weight
  - 2. slope of loss function w.r.t node it feeds into
  - 3. slope of activation function at the node it feeds into

<br>

- need to also keep track of the slopes of the loss function w.r.t node values
- slope of node values are the sum of the slopes for all weights that come out of them

# Backpropagation in practice
## Calculating slopes associated with any weight
- gradients for weight is product of:
  - 1. node value feeding into that weight
  - slope of activation function for the node being fed into
  - slope of loss function w.r.t output node

## Backpropagation: Recap
- start at some random set of weights
- use forward propagation to make a prediction
- use backward propagation to calculate the slope of the loss function w.r.t each weight
- multiply that slope by the learning rate, and subtrack from the current weights
- keep going with that cycle until we get to a flat part

## Stochastic gradient descent
- it is common to calculate slopes on only a subset of the data('batch')
- use a different batch of data to calculate the next update
- start over from the beginning once all data is used
- each time through the training data is called an epoch
- when slopes are calculated on one batch at a time: stochastic gradient descent